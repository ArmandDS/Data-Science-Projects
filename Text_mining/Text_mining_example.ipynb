{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template for the homework\n",
    "\n",
    "\n",
    "## Task\n",
    "- Classify each document in one of 20 categories.\n",
    "- The objective is obtain the better accuracy in the test set. You can use any library and model explained in the course.\n",
    "- The delivery are a unique jupiter notebook with all the code. Must run in the course Anaconda environment. Not use additional libraries.\n",
    "- Send the notebook named homework\\_[name]\\_[surename].ipynb to sueiras@gmail.com before November 20th.\n",
    "\n",
    "## Template structure\n",
    "\n",
    "- A Jupiter notebook template is provided to do the task. Structure:\n",
    "  - Read the train and validation data.\n",
    "  - Transform to generate numerical features.: Build your transformations here\n",
    "  - Model: Build your model or models here. Check the accuracy over the validation set.\n",
    "  - Evaluate results: Build your scoring function here and apply it over the test set.\n",
    "- You need to complete the transform and model steps to achieve the best result in the evaluation metric, the accuracy, in test set.\n",
    "- Is completely forbidden load and use the test set except once in the final evaluate results step.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "- Exercise evaluated in 0-10 range points.\n",
    "- To obtain 5 points you must deliver a notebook without errors that provide a solution whit a minimum accuracy of 67%.\n",
    "- If you obtain an accuracy over 87% you have 10 points.\n",
    "- Intermediated accuracies between 67% and 87% obtain intermediated points proportionally, but depending of the quality of the work is possible to reduce or increase a maximum of 2 the points assigned automatically by accuracy. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "from __future__ import print_function\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import spacy\n",
    "en_nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train',\n",
    "                 shuffle=True, random_state=42)\n",
    "\n",
    "print(twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Text encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 160394)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------\n",
    "# Define your own encoding proccess here\n",
    "# ------------------------------------\n",
    "def remove_empty(text_tr, labels):\n",
    "    filtered_text = [] \n",
    "    filtered_labels = []    \n",
    "    for doc, label in zip(text_tr, labels):       \n",
    "        if doc.strip():            \n",
    "            filtered_text.append(doc)            \n",
    "            filtered_labels.append(label)\n",
    "    return filtered_text, filtered_labels\n",
    "\n",
    "def texto_parser(texto):\n",
    "    texto_lemma =  [[x.lemma_ for x in en_nlp(y)] for y in texto]\n",
    "    x_cleaned1 = []\n",
    "    for x in texto_lemma:\n",
    "        x_cleaned1.append([y for y in x if not y in stopwords])\n",
    "    x_cleaned2 = []\n",
    "    for x in x_cleaned1:\n",
    "        x_cleaned2.append([y for y in x if not y in list(string.punctuation)])\n",
    "    x_cleaned3 = []\n",
    "    useless = [\"-PRON-\"]\n",
    "    for x in x_cleaned2:\n",
    "        x_cleaned3.append([y for y in x if not y in useless])\n",
    "    x_cleaned4 = []\n",
    "    for x in x_cleaned3:\n",
    "        x_cleaned4.append([y for y in x if not (\"--\" in y or '\\n' in y) ])\n",
    "    x_cleaned =\" \".join(str(x) for x  in x_cleaned4)\n",
    "    text_l = []\n",
    "    for x in x_cleaned4:\n",
    "        text = \" \".join([word.lower() for word in x ])\n",
    "        text_clean = re.sub('[\\[\\]/{}⋅−_(...)><\\|]+', ' ', text)\n",
    "        text_l.append(\"\".join([word.lower() for word in text_clean]))\n",
    "    return text_l\n",
    "\n",
    "\n",
    "# EXAMPLE OF CODE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "texto_no_empty, y_trn = remove_empty(twenty_train.data, twenty_train.target)\n",
    "texto_clean = texto_parser(texto_no_empty)\n",
    "\n",
    "# Extract word ocurrences\n",
    "vector_tf = TfidfVectorizer( token_pattern=r\"\\S+\")\n",
    "x_train_vec = vector_tf.fit(texto_clean)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def encoding_text(text):\n",
    "    '''\n",
    "    Encoding function\n",
    "        Input: raw text\n",
    "        Output: features to train the model\n",
    "    '''\n",
    "    text_tf = x_train_vec.transform(text)\n",
    "    return text_tf\n",
    "\n",
    "# Encode train\n",
    "X_trn = encoding_text(texto_clean)\n",
    "print(X_trn.shape)\n",
    "# END OF EXAMPLE OF CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 Model and score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ------------------------------------\n",
    "# Put your model or models here\n",
    "# ------------------------------------\n",
    "\n",
    "# EXAMPLE OF CODE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "\n",
    "# Define and fit in one line\n",
    "clf_nb = MultinomialNB(alpha= 0.01)\n",
    "clf_sv = LinearSVC(C=1, multi_class='ovr', dual=True, max_iter=100)\n",
    "clf_pa = PassiveAggressiveClassifier(max_iter=100)\n",
    "# END OF EXAMPLE OF CODE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Score function\n",
    "def score_function(data):\n",
    "    '''\n",
    "    score_function\n",
    "        Input: Raw text data\n",
    "        Ouptut: predicted category for each text\n",
    "    '''\n",
    "\n",
    "    # ------------------------------------\n",
    "    # Define your own score function\n",
    "    # ------------------------------------\n",
    "    \n",
    "    # EXAMPLE OF CODE\n",
    "    # Transformation steps\n",
    "    X_test_tf = encoding_text(data)\n",
    "    # Prediction steps\n",
    "    \n",
    "    predicted = clf.predict(X_test_tf)\n",
    "    # END OF EXAMPLE OF CODE\n",
    "\n",
    "    return predicted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will evaluate 3 model in order to pick up the better:\n",
    " * Support Vector Classifier\n",
    " * MultinomialNB  Classifier\n",
    " * Passive Aggressive Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90701987 0.90432017 0.90467339]\n",
      "Mean score: 0.905 (+/-0.001)\n",
      "[0.91364238 0.91518685 0.91768455]\n",
      "Mean score: 0.916 (+/-0.001)\n",
      "[0.90807947 0.90909091 0.91290494]\n",
      "Mean score: 0.910 (+/-0.001)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.stats import sem\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clfs = [clf_nb, clf_sv, clf_pa]\n",
    "cv = 3\n",
    "for clf in clfs:\n",
    "    scores = cross_val_score(clf, X_trn, y_trn, cv=cv)\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The best Model Is LinearSVC so we will choose it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Evaluate valid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to  make a better estimator we do not have a train/valid data, we will evaluate the estimator with RamdomizedSearch and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise',\n",
       "          estimator=LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=100,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'C': [0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 10], 'dual': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "params =  {'C':[ 0.05, 0.1, 0.25, 0.5, 0.75, 1, 1.5, 2, 10], \n",
    "           \"dual\":[True,False]}\n",
    "random_grid = RandomizedSearchCV(clf_sv, param_distributions=params, cv= 3)\n",
    "\n",
    "random_grid.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161216192328089"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we make the classifier with the best estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = random_grid.best_estimator_.fit(X_trn, y_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 Evaluate test data\n",
    "- Don't edit after this!!!\n",
    "- Execute only ONCE whit the optimal model selected based on the validation accuracy metric calculated over multiple experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test:  0.8506372809346787\n"
     ]
    }
   ],
   "source": [
    "# Test Accuracy\n",
    "twenty_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "predicted = score_function(texto_parser(twenty_test.data))\n",
    "    \n",
    "print('Accuracy test: ', accuracy_score(twenty_test.target, predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
